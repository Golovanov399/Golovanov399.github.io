{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем всё, less показал, что в каждой строчке метка отделена от сообщения табом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'Ok lar... Joking wif u oni...', \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'U dun say so early hor... U c already then say...', \"Nah I don't think he goes to usf, he lives around here though\"]\n",
      "[0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "X, y = [], []\n",
    "with open(\"SMSSpamCollection.txt\", \"r\") as f:\n",
    "    for s in f.readlines():\n",
    "        label, text = s.rstrip().split('\\t')\n",
    "        X.append(text)\n",
    "        y.append(1 if label == 'spam' else 0)\n",
    "\n",
    "print X[:5]\n",
    "print y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "features = count_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 8713) 5574\n",
      "[ 0.98041322  0.9421179   0.95158631  0.97608025  0.9639066   0.95038677\n",
      "  0.968107    0.95863465  0.95532864  0.9719125 ]\n",
      "0.961847383452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "print features.shape, len(y)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "cvs = cross_val_score(lr, features, y, cv=10, scoring='f1_macro')\n",
    "print cvs\n",
    "print np.average(cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что мы думаем про эти сообщения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X_test = \"\"\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\n",
    "FreeMsg: Txt: claim your reward of 3 hours talk time\n",
    "Have you visited the last lecture on physics?\n",
    "Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\n",
    "Only 99$\"\"\".split('\\n')\n",
    "lr.fit(features, y)\n",
    "print lr.predict(count_vectorizer.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удивительно, но 4 сообщение не спам как будто бы. Видимо, недообучили"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_grams(*args, **kwargs):\n",
    "    cv = CountVectorizer(ngram_range=args)\n",
    "    Xs = cv.fit_transform(X)\n",
    "    if kwargs.get('is_mult'):\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        mnb = MultinomialNB()\n",
    "        cvs = cross_val_score(mnb, Xs, y, cv=10, scoring='f1_macro')\n",
    "        return np.average(cvs)\n",
    "    else:\n",
    "        lr = LogisticRegression()\n",
    "        cvs = cross_val_score(lr, Xs, y, cv=10, scoring='f1_macro')\n",
    "        return np.average(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899824452858\n",
      "0.846370632349\n",
      "0.957240374294\n",
      "0.777510604526\n",
      "0.521830718622\n",
      "0.93427411872\n",
      "0.957781061319\n"
     ]
    }
   ],
   "source": [
    "print test_grams(2, 2)\n",
    "print test_grams(3, 3)\n",
    "print test_grams(1, 3)\n",
    "print test_grams(2, 2, is_mult=True)\n",
    "print test_grams(3, 3, is_mult=True)\n",
    "print test_grams(1, 3, is_mult=True)\n",
    "print test_grams(1, 1, is_mult=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И правда, наивный Байес не особенно приветствует биграммы, а особенно триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916619335048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "fs = tfidf.fit_transform(X)\n",
    "lr = LogisticRegression()\n",
    "cvs = cross_val_score(lr, fs, y, cv=10, scoring='f1_macro')\n",
    "print np.average(cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**: униграммы нужны, без них тяжело, логистическая регрессия лучше Байеса умеет выживать в условиях нехватки ресурсов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
